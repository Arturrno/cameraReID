"""
PyQt6 Multi-Camera Face Re-identification GUI Application
==========================================================
A modern desktop application with:
- 2x2 camera grid layout
- Side panel with detected persons
- Add client functionality
- Multi-threaded AI processing with proper synchronization

Architecture:
- FrameGrabber threads: One per camera, grabs latest frame only (no buffer)
- AIProcessor thread: Single thread batches all cameras for GPU efficiency
- Synchronized display: All cameras show frames from same processing cycle

Author: Senior Computer Vision Engineer
Date: 2024
"""

import sys
import cv2
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
import time
import logging
import threading
from queue import Queue, Empty

from PyQt6.QtWidgets import (
    QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout,
    QGridLayout, QLabel, QLineEdit, QPushButton, QScrollArea,
    QFrame, QSplitter, QFileDialog, QMessageBox, QSizePolicy
)
from PyQt6.QtCore import (
    Qt, QThread, pyqtSignal, pyqtSlot, QTimer, QSize, QMutex, QMutexLocker
)
from PyQt6.QtGui import QImage, QPixmap, QFont, QIcon, QPalette, QColor

# Import existing classes from multi_camera_face_reid_optimized
from multi_camera_face_reid_optimized import (
    OptimizedConfig as Config, 
    RobustFaceDetector, 
    OptimizedFaceEmbeddingEngine as RobustFaceEmbeddingEngine,
    OptimizedFaceGallery as RobustFaceGallery, 
    FaceDetection, 
    TrackedFace, 
    CandidateFace,
    EnhancedPreprocessor
)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ============================================================================
# Data Classes for GUI Communication
# ============================================================================

@dataclass
class PersonInfo:
    """Information about a detected person for GUI display."""
    person_id: int
    is_confirmed: bool
    face_thumbnail: np.ndarray
    first_name: str = ""
    last_name: str = ""
    last_seen_camera: int = -1
    last_seen_time: float = 0.0


# ============================================================================
# Frame Grabber Thread - One per camera, only grabs latest frame
# ============================================================================

class FrameGrabber(threading.Thread):
    """
    Lightweight thread that continuously grabs frames from a camera.
    Always keeps only the LATEST frame - no buffer buildup.
    """
    
    def __init__(self, camera_id: int, url: str, config: Config):
        super().__init__(daemon=True)
        self.camera_id = camera_id
        self.url = url
        self.config = config
        
        self._running = False
        self._connected = False
        self._cap: Optional[cv2.VideoCapture] = None
        
        # Latest frame storage (thread-safe)
        self._frame_lock = threading.Lock()
        self._latest_frame: Optional[np.ndarray] = None
        self._frame_time: float = 0.0
        
        self.logger = logging.getLogger(f"FrameGrabber-{camera_id}")
    
    def connect(self) -> bool:
        """Connect to the camera stream."""
        try:
            self.logger.info(f"Connecting to camera {self.camera_id}...")
            
            if self._cap is not None:
                self._cap.release()
            
            # Set TCP transport for reliability
            import os
            os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = "rtsp_transport;tcp"
            
            self._cap = cv2.VideoCapture(self.url, cv2.CAP_FFMPEG)
            
            # Minimal buffer - we only want latest frame
            self._cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            self._cap.set(cv2.CAP_PROP_OPEN_TIMEOUT_MSEC, 15000)
            self._cap.set(cv2.CAP_PROP_READ_TIMEOUT_MSEC, 5000)
            self._cap.set(cv2.CAP_PROP_HW_ACCELERATION, cv2.VIDEO_ACCELERATION_ANY)
            
            if self._cap.isOpened():
                width = int(self._cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(self._cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                fps = self._cap.get(cv2.CAP_PROP_FPS)
                self.logger.info(f"Camera {self.camera_id} connected: {width}x{height} @ {fps:.1f}fps")
                self._connected = True
                return True
            else:
                self.logger.error(f"Failed to open camera {self.camera_id}")
                self._connected = False
                return False
                
        except Exception as e:
            self.logger.error(f"Connection error: {e}")
            self._connected = False
            return False
    
    def get_latest_frame(self) -> Tuple[Optional[np.ndarray], float]:
        """Get the latest frame (thread-safe). Returns (frame, timestamp)."""
        with self._frame_lock:
            if self._latest_frame is not None:
                return self._latest_frame.copy(), self._frame_time
            return None, 0.0
    
    def is_connected(self) -> bool:
        return self._connected
    
    def run(self):
        """Continuously grab frames, keeping only the latest."""
        self._running = True
        reconnect_attempts = 0
        
        while self._running:
            if not self._connected:
                if reconnect_attempts >= self.config.MAX_RECONNECT_ATTEMPTS:
                    self.logger.error("Max reconnection attempts reached")
                    break
                reconnect_attempts += 1
                if self.connect():
                    reconnect_attempts = 0
                else:
                    time.sleep(self.config.RECONNECT_DELAY)
                continue
            
            try:
                ret, frame = self._cap.read()
                
                if not ret or frame is None:
                    self._connected = False
                    continue
                
                # Skip corrupted frames
                if frame.size == 0:
                    continue
                
                # Store latest frame (overwrites previous - no buffer buildup!)
                with self._frame_lock:
                    self._latest_frame = frame
                    self._frame_time = time.time()
                    
            except Exception as e:
                self.logger.error(f"Frame grab error: {e}")
                self._connected = False
        
        if self._cap is not None:
            self._cap.release()
    
    def stop(self):
        self._running = False


# ============================================================================
# AI Processor Thread - Single thread for all cameras (GPU efficiency)
# ============================================================================

class AIProcessor(QThread):
    """
    Single AI processing thread that handles ALL cameras.
    Batches frames together for maximum GPU utilization.
    Emits synchronized results for all cameras.
    """
    
    # Signals
    frames_ready = pyqtSignal(dict)  # {camera_id: processed_frame}
    detections_ready = pyqtSignal(int, list)  # camera_id, detections
    connection_status = pyqtSignal(int, bool)  # camera_id, connected
    
    def __init__(self, grabbers: List[FrameGrabber], config: Config,
                 detector: RobustFaceDetector,
                 embedding_engine: RobustFaceEmbeddingEngine,
                 gallery: RobustFaceGallery,
                 parent=None):
        super().__init__(parent)
        
        self.grabbers = grabbers
        self.config = config
        self.detector = detector
        self.embedding_engine = embedding_engine
        self.gallery = gallery
        
        self._running = False
        self._frame_count = 0
        
        self.logger = logging.getLogger("AIProcessor")
    
    def _draw_detections(self, frame: np.ndarray, 
                         reid_detections: List[FaceDetection],
                         small_detections: List[FaceDetection]) -> np.ndarray:
        """Draw bounding boxes and labels on frame."""
        COLORS = [
            (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),
            (255, 0, 255), (0, 255, 255), (128, 0, 0), (0, 128, 0),
        ]
        CANDIDATE_COLOR = (128, 128, 128)
        TOO_SMALL_COLOR = (100, 100, 100)
        
        for detection in reid_detections:
            x1, y1, x2, y2 = detection.bbox
            person_id = detection.person_id or 0
            
            if detection.is_confirmed:
                color = COLORS[person_id % len(COLORS)]
                label = f"ID: {person_id}"
            else:
                color = CANDIDATE_COLOR
                label = f"ID: ? ({abs(person_id)})"
            
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            cv2.rectangle(frame, (x1, y1 - label_h - 10), (x1 + label_w + 5, y1), color, -1)
            cv2.putText(frame, label, (x1 + 2, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        for detection in small_detections:
            x1, y1, x2, y2 = detection.bbox
            cv2.rectangle(frame, (x1, y1), (x2, y2), TOO_SMALL_COLOR, 1)
        
        return frame
    
    def run(self):
        """Main processing loop - processes all cameras synchronously."""
        self._running = True
        self.logger.info("AI Processor started")
        
        while self._running:
            self._frame_count += 1
            
            # Skip frames for performance
            if self._frame_count % self.config.FRAME_SKIP != 0:
                time.sleep(0.01)  # Small sleep to not spin CPU
                continue
            
            # Collect latest frames from ALL cameras simultaneously
            frames_to_process: Dict[int, np.ndarray] = {}
            
            for grabber in self.grabbers:
                if grabber is None:
                    continue
                    
                frame, frame_time = grabber.get_latest_frame()
                camera_id = grabber.camera_id
                
                # Emit connection status
                self.connection_status.emit(camera_id, grabber.is_connected())
                
                if frame is not None:
                    # Only process recent frames (drop if too old - sync!)
                    if time.time() - frame_time < 0.5:  # Max 500ms old
                        frames_to_process[camera_id] = frame
            
            if not frames_to_process:
                time.sleep(0.01)
                continue
            
            # Process all frames
            processed_frames: Dict[int, np.ndarray] = {}
            
            # Process each camera separately to maintain proper per-camera preprocessing
            for camera_id, frame in frames_to_process.items():
                # Update camera stats
                self.embedding_engine.update_camera_stats(camera_id, frame)
                
                # Detect faces
                all_detections = self.detector.detect(frame)
                reid_detections, small_detections = self.detector.filter_for_reid(all_detections)
                
                # Track list for IOU updates
                current_tracks: List[Tuple[int, Tuple[int, int, int, int]]] = []
                
                if reid_detections:
                    # Extract embeddings with CORRECT camera_id for preprocessing
                    face_crops = [d.face_crop for d in reid_detections]
                    embeddings = self.embedding_engine.extract_embeddings_batch(face_crops, camera_id)
                    
                    # Match and update gallery
                    for detection, embedding in zip(reid_detections, embeddings):
                        detection.embedding = embedding
                        person_id, is_confirmed = self.gallery.match_and_update(
                            embedding, detection.bbox, camera_id
                        )
                        detection.person_id = person_id
                        detection.is_confirmed = is_confirmed
                        
                        # Add to track list for IOU memory
                        if is_confirmed:
                            current_tracks.append((person_id, detection.bbox))
                
                # Update IOU track memory
                self.gallery.update_tracks(camera_id, current_tracks)
                
                # Draw and store
                processed_frame = self._draw_detections(frame.copy(), reid_detections, small_detections)
                processed_frames[camera_id] = processed_frame
                
                # Emit detections
                if reid_detections:
                    self.detections_ready.emit(camera_id, reid_detections)
            
            # Emit all processed frames at once (synchronized!)
            self.frames_ready.emit(processed_frames)
            
            # Small sleep to control frame rate
            time.sleep(0.01)
        
        self.logger.info("AI Processor stopped")
    
    def stop(self):
        self._running = False


# ============================================================================
# Legacy CameraWorker wrapper (for compatibility)
# ============================================================================

class CameraWorker:
    """Compatibility wrapper - not used in new architecture."""
    pass


# ============================================================================
# Camera Display Widget
# ============================================================================

class CameraWidget(QFrame):
    """Widget for displaying a single camera stream."""
    
    def __init__(self, camera_id: int, parent=None):
        super().__init__(parent)
        self.camera_id = camera_id
        self._setup_ui()
    
    def _setup_ui(self):
        """Setup the widget UI."""
        self.setFrameStyle(QFrame.Shape.Box | QFrame.Shadow.Sunken)
        self.setLineWidth(2)
        
        layout = QVBoxLayout(self)
        layout.setContentsMargins(2, 2, 2, 2)
        layout.setSpacing(2)
        
        # Camera label (title)
        self.title_label = QLabel(f"Kamera {self.camera_id + 1}")
        self.title_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.title_label.setFont(QFont("Arial", 10, QFont.Weight.Bold))
        self.title_label.setStyleSheet("color: white; background-color: #2c3e50; padding: 5px;")
        layout.addWidget(self.title_label)
        
        # Video display label
        self.video_label = QLabel()
        self.video_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.video_label.setMinimumSize(480, 360)  # Higher minimum for better quality
        self.video_label.setSizePolicy(QSizePolicy.Policy.Expanding, QSizePolicy.Policy.Expanding)
        self.video_label.setStyleSheet("background-color: #1a1a2e;")
        self.video_label.setText("ÅÄ…czenie...")
        self.video_label.setScaledContents(False)  # We handle scaling manually
        layout.addWidget(self.video_label)
        
        # Status label
        self.status_label = QLabel("Status: RozÅ‚Ä…czony")
        self.status_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.status_label.setStyleSheet("color: #e74c3c; font-size: 10px;")
        layout.addWidget(self.status_label)
    
    def update_frame(self, frame: np.ndarray):
        """Update the displayed frame with high quality scaling."""
        # Convert BGR to RGB
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # Get widget size
        label_size = self.video_label.size()
        
        # Original frame dimensions
        h, w = rgb_frame.shape[:2]
        
        # Calculate scale to fit widget while maintaining aspect ratio
        scale = min(label_size.width() / w, label_size.height() / h)
        new_w, new_h = int(w * scale), int(h * scale)
        
        if new_w > 0 and new_h > 0:
            # Use INTER_AREA for downscaling (better quality) or INTER_CUBIC for upscaling
            if scale < 1.0:
                # Downscaling - INTER_AREA gives best results
                resized = cv2.resize(rgb_frame, (new_w, new_h), interpolation=cv2.INTER_AREA)
            else:
                # Upscaling - INTER_CUBIC for better quality
                resized = cv2.resize(rgb_frame, (new_w, new_h), interpolation=cv2.INTER_CUBIC)
            
            # Ensure contiguous array for QImage
            resized = np.ascontiguousarray(resized)
            
            # Convert to QImage
            bytes_per_line = 3 * new_w
            q_image = QImage(resized.data, new_w, new_h, bytes_per_line, QImage.Format.Format_RGB888)
            
            # Create a copy to avoid memory issues
            pixmap = QPixmap.fromImage(q_image.copy())
            
            # Set pixmap
            self.video_label.setPixmap(pixmap)
    
    def set_connected(self, connected: bool):
        """Update connection status."""
        if connected:
            self.status_label.setText("Status: PoÅ‚Ä…czony")
            self.status_label.setStyleSheet("color: #27ae60; font-size: 10px;")
        else:
            self.status_label.setText("Status: RozÅ‚Ä…czony")
            self.status_label.setStyleSheet("color: #e74c3c; font-size: 10px;")
            self.video_label.setText("ÅÄ…czenie...")
    
    def set_status(self, status: str):
        """Set a custom status for the camera (e.g., DISABLED)."""
        if status == "DISABLED":
            self.status_label.setText("Status: WyÅ‚Ä…czona")
            self.status_label.setStyleSheet("color: #7f8c8d; font-size: 10px;")
            self.video_label.setText("Kamera wyÅ‚Ä…czona")
            self.video_label.setStyleSheet("background-color: #2c2c2c; color: #7f8c8d;")
    
    def set_error(self, error_msg: str):
        """Display error message."""
        self.status_label.setText(f"BÅ‚Ä…d: {error_msg[:30]}...")
        self.status_label.setStyleSheet("color: #e74c3c; font-size: 10px;")


# ============================================================================
# Person Card Widget
# ============================================================================

class PersonCardWidget(QFrame):
    """Widget for displaying a single person in the sidebar."""
    
    clicked = pyqtSignal(int)  # person_id
    
    def __init__(self, person_info: PersonInfo, parent=None):
        super().__init__(parent)
        self.person_info = person_info
        self._setup_ui()
    
    def _setup_ui(self):
        """Setup the widget UI."""
        self.setFrameStyle(QFrame.Shape.Box | QFrame.Shadow.Raised)
        self.setLineWidth(1)
        self.setCursor(Qt.CursorShape.PointingHandCursor)
        
        # Set style based on confirmation status
        if self.person_info.is_confirmed:
            self.setStyleSheet("""
                PersonCardWidget {
                    background-color: #2d3436;
                    border: 2px solid #27ae60;
                    border-radius: 5px;
                    margin: 2px;
                }
                PersonCardWidget:hover {
                    background-color: #3d4446;
                }
            """)
        else:
            self.setStyleSheet("""
                PersonCardWidget {
                    background-color: #2d3436;
                    border: 2px solid #f39c12;
                    border-radius: 5px;
                    margin: 2px;
                }
                PersonCardWidget:hover {
                    background-color: #3d4446;
                }
            """)
        
        layout = QHBoxLayout(self)
        layout.setContentsMargins(5, 5, 5, 5)
        layout.setSpacing(10)
        
        # Face thumbnail
        self.thumbnail_label = QLabel()
        self.thumbnail_label.setFixedSize(60, 60)
        self.thumbnail_label.setStyleSheet("border: 1px solid #7f8c8d; border-radius: 3px;")
        self._update_thumbnail()
        layout.addWidget(self.thumbnail_label)
        
        # Info layout
        info_layout = QVBoxLayout()
        info_layout.setSpacing(2)
        
        # ID / Name
        if self.person_info.first_name or self.person_info.last_name:
            name = f"{self.person_info.first_name} {self.person_info.last_name}".strip()
        else:
            if self.person_info.is_confirmed:
                name = f"ID: {self.person_info.person_id}"
            else:
                name = f"Kandydat #{abs(self.person_info.person_id)}"
        
        self.name_label = QLabel(name)
        self.name_label.setFont(QFont("Arial", 11, QFont.Weight.Bold))
        self.name_label.setStyleSheet("color: white;")
        info_layout.addWidget(self.name_label)
        
        # Status
        status = "âœ“ Potwierdzony" if self.person_info.is_confirmed else "â³ Kandydat"
        self.status_label = QLabel(status)
        self.status_label.setStyleSheet(
            "color: #27ae60;" if self.person_info.is_confirmed else "color: #f39c12;"
        )
        info_layout.addWidget(self.status_label)
        
        # Camera info
        cam_text = f"Kamera: {self.person_info.last_seen_camera + 1}"
        self.camera_label = QLabel(cam_text)
        self.camera_label.setStyleSheet("color: #95a5a6; font-size: 10px;")
        info_layout.addWidget(self.camera_label)
        
        layout.addLayout(info_layout)
        layout.addStretch()
    
    def _update_thumbnail(self):
        """Update the face thumbnail."""
        if self.person_info.face_thumbnail is not None:
            thumb = self.person_info.face_thumbnail
            
            # Resize to fit
            thumb_resized = cv2.resize(thumb, (60, 60), interpolation=cv2.INTER_LINEAR)
            rgb_thumb = cv2.cvtColor(thumb_resized, cv2.COLOR_BGR2RGB)
            
            h, w = rgb_thumb.shape[:2]
            bytes_per_line = 3 * w
            q_image = QImage(rgb_thumb.data, w, h, bytes_per_line, QImage.Format.Format_RGB888)
            
            self.thumbnail_label.setPixmap(QPixmap.fromImage(q_image))
        else:
            self.thumbnail_label.setText("?")
            self.thumbnail_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
    
    def mousePressEvent(self, event):
        """Handle mouse click."""
        self.clicked.emit(self.person_info.person_id)
        super().mousePressEvent(event)
    
    def update_info(self, person_info: PersonInfo):
        """Update person information."""
        self.person_info = person_info
        self._update_thumbnail()
        
        if person_info.first_name or person_info.last_name:
            name = f"{person_info.first_name} {person_info.last_name}".strip()
        else:
            if person_info.is_confirmed:
                name = f"ID: {person_info.person_id}"
            else:
                name = f"Kandydat #{abs(person_info.person_id)}"
        
        self.name_label.setText(name)


# ============================================================================
# Sidebar Panel
# ============================================================================

class SidebarPanel(QFrame):
    """Side panel with detected persons list and add client form."""
    
    person_selected = pyqtSignal(int)  # person_id
    client_added = pyqtSignal(int, str, str)  # person_id, first_name, last_name
    photo_uploaded = pyqtSignal(str)  # file_path
    
    def __init__(self, parent=None):
        super().__init__(parent)
        self._person_cards: Dict[int, PersonCardWidget] = {}
        self._selected_person_id: Optional[int] = None
        self._setup_ui()
    
    def _setup_ui(self):
        """Setup the sidebar UI."""
        self.setMinimumWidth(280)
        self.setMaximumWidth(350)
        self.setStyleSheet("background-color: #1e272e;")
        
        layout = QVBoxLayout(self)
        layout.setContentsMargins(10, 10, 10, 10)
        layout.setSpacing(10)
        
        # ===== Persons Section =====
        persons_header = QLabel("ðŸ‘¥ Osoby")
        persons_header.setFont(QFont("Arial", 14, QFont.Weight.Bold))
        persons_header.setStyleSheet("color: white; padding: 5px;")
        layout.addWidget(persons_header)
        
        # Scroll area for persons
        self.scroll_area = QScrollArea()
        self.scroll_area.setWidgetResizable(True)
        self.scroll_area.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOff)
        self.scroll_area.setStyleSheet("""
            QScrollArea {
                border: none;
                background-color: #1e272e;
            }
            QScrollBar:vertical {
                background-color: #2d3436;
                width: 10px;
            }
            QScrollBar::handle:vertical {
                background-color: #636e72;
                border-radius: 5px;
            }
        """)
        
        self.persons_container = QWidget()
        self.persons_layout = QVBoxLayout(self.persons_container)
        self.persons_layout.setContentsMargins(0, 0, 0, 0)
        self.persons_layout.setSpacing(5)
        self.persons_layout.addStretch()
        
        self.scroll_area.setWidget(self.persons_container)
        layout.addWidget(self.scroll_area, stretch=1)
        
        # ===== Stats Section =====
        self.stats_label = QLabel("Potwierdzeni: 0 | Kandydaci: 0")
        self.stats_label.setStyleSheet("color: #95a5a6; font-size: 11px;")
        self.stats_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        layout.addWidget(self.stats_label)
        
        # ===== Add Client Section =====
        add_client_frame = QFrame()
        add_client_frame.setStyleSheet("""
            QFrame {
                background-color: #2d3436;
                border-radius: 8px;
                padding: 10px;
            }
        """)
        add_client_layout = QVBoxLayout(add_client_frame)
        add_client_layout.setSpacing(8)
        
        add_client_header = QLabel("âž• Dodaj Klienta")
        add_client_header.setFont(QFont("Arial", 12, QFont.Weight.Bold))
        add_client_header.setStyleSheet("color: white;")
        add_client_layout.addWidget(add_client_header)
        
        # Selected person indicator
        self.selected_label = QLabel("Wybierz osobÄ™ z listy powyÅ¼ej")
        self.selected_label.setStyleSheet("color: #f39c12; font-size: 10px;")
        add_client_layout.addWidget(self.selected_label)
        
        # First name input
        self.first_name_input = QLineEdit()
        self.first_name_input.setPlaceholderText("ImiÄ™")
        self.first_name_input.setStyleSheet("""
            QLineEdit {
                background-color: #3d4446;
                color: white;
                border: 1px solid #636e72;
                border-radius: 5px;
                padding: 8px;
                font-size: 12px;
            }
            QLineEdit:focus {
                border: 1px solid #3498db;
            }
        """)
        add_client_layout.addWidget(self.first_name_input)
        
        # Last name input
        self.last_name_input = QLineEdit()
        self.last_name_input.setPlaceholderText("Nazwisko")
        self.last_name_input.setStyleSheet("""
            QLineEdit {
                background-color: #3d4446;
                color: white;
                border: 1px solid #636e72;
                border-radius: 5px;
                padding: 8px;
                font-size: 12px;
            }
            QLineEdit:focus {
                border: 1px solid #3498db;
            }
        """)
        add_client_layout.addWidget(self.last_name_input)
        
        # Buttons layout
        buttons_layout = QHBoxLayout()
        
        # Add client button
        self.add_button = QPushButton("Dodaj Klienta")
        self.add_button.setStyleSheet("""
            QPushButton {
                background-color: #27ae60;
                color: white;
                border: none;
                border-radius: 5px;
                padding: 10px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #2ecc71;
            }
            QPushButton:pressed {
                background-color: #1e8449;
            }
            QPushButton:disabled {
                background-color: #636e72;
            }
        """)
        self.add_button.clicked.connect(self._on_add_client)
        self.add_button.setEnabled(False)
        buttons_layout.addWidget(self.add_button)
        
        # Upload photo button
        self.upload_button = QPushButton("ðŸ“·")
        self.upload_button.setFixedWidth(40)
        self.upload_button.setToolTip("Wczytaj zdjÄ™cie z dysku")
        self.upload_button.setStyleSheet("""
            QPushButton {
                background-color: #3498db;
                color: white;
                border: none;
                border-radius: 5px;
                padding: 10px;
                font-size: 14px;
            }
            QPushButton:hover {
                background-color: #5dade2;
            }
            QPushButton:pressed {
                background-color: #2980b9;
            }
        """)
        self.upload_button.clicked.connect(self._on_upload_photo)
        buttons_layout.addWidget(self.upload_button)
        
        add_client_layout.addLayout(buttons_layout)
        layout.addWidget(add_client_frame)
    
    def add_or_update_person(self, person_info: PersonInfo):
        """Add a new person or update existing one."""
        person_id = person_info.person_id
        
        if person_id in self._person_cards:
            # Update existing card
            self._person_cards[person_id].update_info(person_info)
        else:
            # Create new card
            card = PersonCardWidget(person_info)
            card.clicked.connect(self._on_person_clicked)
            
            # Insert before the stretch
            self.persons_layout.insertWidget(
                self.persons_layout.count() - 1, card
            )
            self._person_cards[person_id] = card
    
    def remove_person(self, person_id: int):
        """Remove a person from the list."""
        if person_id in self._person_cards:
            card = self._person_cards.pop(person_id)
            card.deleteLater()
            
            if self._selected_person_id == person_id:
                self._selected_person_id = None
                self._update_selection_ui()
    
    def update_stats(self, confirmed: int, candidates: int):
        """Update statistics label."""
        self.stats_label.setText(f"Potwierdzeni: {confirmed} | Kandydaci: {candidates}")
    
    def _on_person_clicked(self, person_id: int):
        """Handle person card click."""
        self._selected_person_id = person_id
        self._update_selection_ui()
        self.person_selected.emit(person_id)
    
    def _update_selection_ui(self):
        """Update UI to reflect current selection."""
        if self._selected_person_id is not None:
            card = self._person_cards.get(self._selected_person_id)
            if card:
                info = card.person_info
                if info.first_name or info.last_name:
                    name = f"{info.first_name} {info.last_name}".strip()
                else:
                    name = f"ID: {info.person_id}" if info.is_confirmed else f"Kandydat #{abs(info.person_id)}"
                self.selected_label.setText(f"Wybrano: {name}")
                self.selected_label.setStyleSheet("color: #27ae60; font-size: 10px;")
                self.add_button.setEnabled(True)
            else:
                self._selected_person_id = None
                self.selected_label.setText("Wybierz osobÄ™ z listy powyÅ¼ej")
                self.selected_label.setStyleSheet("color: #f39c12; font-size: 10px;")
                self.add_button.setEnabled(False)
        else:
            self.selected_label.setText("Wybierz osobÄ™ z listy powyÅ¼ej")
            self.selected_label.setStyleSheet("color: #f39c12; font-size: 10px;")
            self.add_button.setEnabled(False)
    
    def _on_add_client(self):
        """Handle add client button click."""
        if self._selected_person_id is None:
            return
        
        first_name = self.first_name_input.text().strip()
        last_name = self.last_name_input.text().strip()
        
        if not first_name and not last_name:
            QMessageBox.warning(
                self, "BÅ‚Ä…d",
                "ProszÄ™ podaÄ‡ imiÄ™ lub nazwisko."
            )
            return
        
        self.client_added.emit(self._selected_person_id, first_name, last_name)
        
        # Clear inputs
        self.first_name_input.clear()
        self.last_name_input.clear()
    
    def _on_upload_photo(self):
        """Handle upload photo button click."""
        file_path, _ = QFileDialog.getOpenFileName(
            self,
            "Wybierz zdjÄ™cie",
            "",
            "Obrazy (*.png *.jpg *.jpeg *.bmp)"
        )
        
        if file_path:
            self.photo_uploaded.emit(file_path)


# ============================================================================
# Main Window
# ============================================================================

class MainWindow(QMainWindow):
    """Main application window."""
    
    def __init__(self):
        super().__init__()
        
        # Initialize AI components
        self.config = Config()
        
        # Only use cameras that are actually configured (don't extend to 4)
        self.num_active_cameras = len(self.config.CAMERA_URLS)
        logger.info(f"Configured cameras: {self.num_active_cameras}")
        
        logger.info("Loading AI models...")
        self.detector = RobustFaceDetector(self.config)
        self.embedding_engine = RobustFaceEmbeddingEngine(self.config)
        self.gallery = RobustFaceGallery(self.config)
        logger.info("AI models loaded successfully")
        
        # Person name mapping
        self._person_names: Dict[int, Tuple[str, str]] = {}  # person_id -> (first, last)
        
        # Frame grabbers (one per camera)
        self.frame_grabbers: List[Optional[FrameGrabber]] = []
        
        # AI Processor (single thread for all cameras)
        self.ai_processor: Optional[AIProcessor] = None
        
        # Setup UI
        self._setup_ui()
        self._setup_camera_system()
        
        # Setup update timer for stats
        self.stats_timer = QTimer(self)
        self.stats_timer.timeout.connect(self._update_stats)
        self.stats_timer.start(1000)  # Update every second
    
    def _setup_ui(self):
        """Setup the main window UI."""
        self.setWindowTitle("Multi-Camera Face Re-identification System")
        self.setMinimumSize(1600, 900)  # Larger minimum for better video quality
        self.resize(1920, 1080)  # Default to Full HD
        self.setStyleSheet("background-color: #0f0f1a;")
        
        # Central widget
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        # Main horizontal layout
        main_layout = QHBoxLayout(central_widget)
        main_layout.setContentsMargins(10, 10, 10, 10)
        main_layout.setSpacing(10)
        
        # ===== Left side: Camera Grid =====
        camera_container = QWidget()
        camera_layout = QGridLayout(camera_container)
        camera_layout.setSpacing(10)
        
        # Create 4 camera widgets in 2x2 grid
        self.camera_widgets: List[CameraWidget] = []
        for i in range(4):
            camera_widget = CameraWidget(i)
            row, col = i // 2, i % 2
            camera_layout.addWidget(camera_widget, row, col)
            self.camera_widgets.append(camera_widget)
        
        main_layout.addWidget(camera_container, stretch=3)
        
        # ===== Right side: Sidebar =====
        self.sidebar = SidebarPanel()
        self.sidebar.person_selected.connect(self._on_person_selected)
        self.sidebar.client_added.connect(self._on_client_added)
        self.sidebar.photo_uploaded.connect(self._on_photo_uploaded)
        main_layout.addWidget(self.sidebar)
    
    def _setup_camera_system(self):
        """Create frame grabbers and AI processor with new architecture."""
        # Create frame grabbers for each active camera
        for i in range(4):
            if i < self.num_active_cameras:
                url = self.config.CAMERA_URLS[i]
                grabber = FrameGrabber(camera_id=i, url=url, config=self.config)
                grabber.start()
                self.frame_grabbers.append(grabber)
                logger.info(f"Started frame grabber {i}")
            else:
                self.frame_grabbers.append(None)
                self.camera_widgets[i].set_status("DISABLED")
                logger.info(f"Camera {i} is disabled")
        
        # Give grabbers time to connect
        time.sleep(0.5)
        
        # Create single AI processor for all cameras
        active_grabbers = [g for g in self.frame_grabbers if g is not None]
        self.ai_processor = AIProcessor(
            grabbers=active_grabbers,
            config=self.config,
            detector=self.detector,
            embedding_engine=self.embedding_engine,
            gallery=self.gallery
        )
        
        # Connect AI processor signals
        self.ai_processor.frames_ready.connect(self._on_frames_ready)
        self.ai_processor.detections_ready.connect(self._on_detections_ready)
        self.ai_processor.connection_status.connect(self._on_connection_status)
        
        self.ai_processor.start()
        logger.info("Started AI processor (batched processing for all cameras)")
    
    @pyqtSlot(dict)
    def _on_frames_ready(self, frames: Dict[int, np.ndarray]):
        """Handle synchronized frames from all cameras."""
        for camera_id, frame in frames.items():
            if 0 <= camera_id < len(self.camera_widgets):
                self.camera_widgets[camera_id].update_frame(frame)
    
    @pyqtSlot(int, list)
    def _on_detections_ready(self, camera_id: int, detections: List[FaceDetection]):
        """Handle new detections from camera worker."""
        for detection in detections:
            if detection.person_id is not None and detection.face_crop is not None:
                # Get name if assigned
                first_name, last_name = self._person_names.get(
                    detection.person_id, ("", "")
                )
                
                person_info = PersonInfo(
                    person_id=detection.person_id,
                    is_confirmed=detection.is_confirmed,
                    face_thumbnail=detection.face_crop.copy(),
                    first_name=first_name,
                    last_name=last_name,
                    last_seen_camera=camera_id,
                    last_seen_time=time.time()
                )
                
                self.sidebar.add_or_update_person(person_info)
    
    @pyqtSlot(int, bool)
    def _on_connection_status(self, camera_id: int, connected: bool):
        """Handle camera connection status change."""
        if 0 <= camera_id < len(self.camera_widgets):
            self.camera_widgets[camera_id].set_connected(connected)
    
    @pyqtSlot(int, str)
    def _on_error_occurred(self, camera_id: int, error_msg: str):
        """Handle camera error."""
        logger.error(f"Camera {camera_id} error: {error_msg}")
        if 0 <= camera_id < len(self.camera_widgets):
            self.camera_widgets[camera_id].set_error(error_msg)
    
    @pyqtSlot(int)
    def _on_person_selected(self, person_id: int):
        """Handle person selection in sidebar."""
        logger.info(f"Person selected: {person_id}")
    
    @pyqtSlot(int, str, str)
    def _on_client_added(self, person_id: int, first_name: str, last_name: str):
        """Handle client addition."""
        logger.info(f"Adding client: {first_name} {last_name} to person {person_id}")
        
        # Store the name mapping
        self._person_names[person_id] = (first_name, last_name)
        
        # Update the sidebar card if it exists
        cards = self.sidebar._person_cards
        if person_id in cards:
            card = cards[person_id]
            card.person_info.first_name = first_name
            card.person_info.last_name = last_name
            card.update_info(card.person_info)
        
        QMessageBox.information(
            self,
            "Sukces",
            f"Przypisano dane klienta:\n{first_name} {last_name}"
        )
    
    @pyqtSlot(str)
    def _on_photo_uploaded(self, file_path: str):
        """Handle photo upload."""
        logger.info(f"Photo uploaded: {file_path}")
        
        try:
            # Load image
            image = cv2.imread(file_path)
            if image is None:
                QMessageBox.warning(self, "BÅ‚Ä…d", "Nie moÅ¼na wczytaÄ‡ obrazu.")
                return
            
            # Detect faces in uploaded image
            detections = self.detector.detect(image)
            reid_detections, _ = self.detector.filter_for_reid(detections)
            
            if not reid_detections:
                QMessageBox.warning(
                    self,
                    "Brak twarzy",
                    "Nie wykryto twarzy na wczytanym zdjÄ™ciu."
                )
                return
            
            # Use the first (largest) face
            detection = max(reid_detections, key=lambda d: d.area)
            
            # Extract embedding
            embedding = self.embedding_engine.extract_embedding(detection.face_crop)
            
            # Add to gallery
            person_id, is_confirmed = self.gallery.match_and_update(
                embedding, detection.bbox, camera_id=-1
            )
            
            # Create person info
            first_name, last_name = self._person_names.get(person_id, ("", ""))
            person_info = PersonInfo(
                person_id=person_id,
                is_confirmed=is_confirmed,
                face_thumbnail=detection.face_crop.copy(),
                first_name=first_name,
                last_name=last_name,
                last_seen_camera=-1,
                last_seen_time=time.time()
            )
            
            self.sidebar.add_or_update_person(person_info)
            
            QMessageBox.information(
                self,
                "Sukces",
                f"Dodano twarz ze zdjÄ™cia.\n"
                f"{'ID: ' + str(person_id) if is_confirmed else 'Kandydat #' + str(abs(person_id))}"
            )
            
        except Exception as e:
            logger.error(f"Error processing uploaded photo: {e}")
            QMessageBox.warning(self, "BÅ‚Ä…d", f"BÅ‚Ä…d przetwarzania: {str(e)}")
    
    def _update_stats(self):
        """Update gallery statistics in sidebar."""
        stats = self.gallery.get_stats()
        self.sidebar.update_stats(
            stats['confirmed_faces'],
            stats['candidates']
        )
    
    def closeEvent(self, event):
        """Handle window close event."""
        logger.info("Closing application...")
        
        # Stop AI processor
        if self.ai_processor is not None:
            self.ai_processor.stop()
            self.ai_processor.wait(2000)
        
        # Stop all frame grabbers
        for grabber in self.frame_grabbers:
            if grabber is not None:
                grabber.stop()
        
        # Wait for grabbers to finish
        for grabber in self.frame_grabbers:
            if grabber is not None:
                grabber.join(timeout=2.0)
        
        logger.info("Application closed")
        event.accept()


# ============================================================================
# Entry Point
# ============================================================================

def main():
    """Main entry point."""
    print("=" * 70)
    print("Multi-Camera Face Re-identification System - PyQt6 GUI")
    print("=" * 70)
    print()
    
    # Create application
    app = QApplication(sys.argv)
    
    # Set application style
    app.setStyle("Fusion")
    
    # Dark palette
    palette = QPalette()
    palette.setColor(QPalette.ColorRole.Window, QColor(15, 15, 26))
    palette.setColor(QPalette.ColorRole.WindowText, QColor(255, 255, 255))
    palette.setColor(QPalette.ColorRole.Base, QColor(30, 39, 46))
    palette.setColor(QPalette.ColorRole.AlternateBase, QColor(45, 52, 54))
    palette.setColor(QPalette.ColorRole.ToolTipBase, QColor(255, 255, 255))
    palette.setColor(QPalette.ColorRole.ToolTipText, QColor(255, 255, 255))
    palette.setColor(QPalette.ColorRole.Text, QColor(255, 255, 255))
    palette.setColor(QPalette.ColorRole.Button, QColor(45, 52, 54))
    palette.setColor(QPalette.ColorRole.ButtonText, QColor(255, 255, 255))
    palette.setColor(QPalette.ColorRole.BrightText, QColor(255, 0, 0))
    palette.setColor(QPalette.ColorRole.Link, QColor(52, 152, 219))
    palette.setColor(QPalette.ColorRole.Highlight, QColor(52, 152, 219))
    palette.setColor(QPalette.ColorRole.HighlightedText, QColor(255, 255, 255))
    app.setPalette(palette)
    
    # Create and show main window
    window = MainWindow()
    window.show()
    
    # Run application
    sys.exit(app.exec())


if __name__ == "__main__":
    main()
